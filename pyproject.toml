[project]
name = "meet-transcript-whisper"
version = "0.1.0"
description = "Meeting Transcription API with Speaker Diarization using Whisper and pyannote.audio"
readme = "README.md"
requires-python = ">=3.12"
dependencies = [
    # Web framework
    "fastapi>=0.115.0",
    "uvicorn[standard]>=0.32.0",
    "python-multipart>=0.0.12",
    # ML/Audio
    "openai-whisper>=20240930",
    "pyannote-audio>=3.3.0",
    "torch>=2.0.0",
    "torchaudio>=2.0.0",
    "pydub>=0.25.1",
    # Task queue
    "celery[redis]>=5.4.0",
    "redis>=5.0.0",
    # Configuration & Logging
    "pydantic-settings>=2.6.0",
    "structlog>=24.4.0",
]

[project.optional-dependencies]
dev = [
    "pre-commit>=4.5.1",
    "ruff>=0.8.0",
    "pytest>=8.3.0",
    "pytest-asyncio>=0.24.0",
    "httpx>=0.27.0",
]

[project.scripts]
meet-transcriber = "src.api.main:main"

[tool.ruff]
line-length = 100
target-version = "py312"

[tool.ruff.lint]
select = ["E", "F", "I", "N", "W", "UP"]

[tool.pytest.ini_options]
asyncio_mode = "auto"
testpaths = ["tests"]
